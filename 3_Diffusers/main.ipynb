{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "!pip install diffusers\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "# We can set the device to either use our GPU or use our CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pipeline\n",
    "image_pipe = DDPMPipeline.from_pretrained(\"google/ddpm-celebahq-256\")\n",
    "image_pipe.to(device)\n",
    "\n",
    "# Sample an image\n",
    "image_pipe().images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](celeb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install genaibook\n",
    "from genaibook.core import plot_noise_and_denoise\n",
    "\n",
    "# The random starting point is a batch of 4 images\n",
    "# Each image is 3-channel (RGB) 256x256 pixel image\n",
    "image = torch.randn(4, 3, 256, 256).to(device)\n",
    "\n",
    "# Set the specific number of diffusion steps\n",
    "image_pipe.scheduler.set_timesteps(num_inference_steps=30)\n",
    "\n",
    "# Loop through the sampling timesteps\n",
    "for i, t in enumerate(image_pipe.scheduler.timesteps):\n",
    "    # Get the prediction given the current sample x and the timestep t\n",
    "    # As we're running inference, we don't need to calculate gradients,\n",
    "    # so we can use torch.no_grad().\n",
    "    with torch.no_grad():\n",
    "        # We need to pass in the timestep t so that the model knows what\n",
    "        # timestep it's currently at. We'll learn more about this in the\n",
    "        # coming sections.\n",
    "        noise_pred = image_pipe.unet(image, t)[\"sample\"]\n",
    "\n",
    "    # Calculate what the updated x should look like with the scheduler\n",
    "    scheduler_output = image_pipe.scheduler.step(noise_pred, t, image)\n",
    "\n",
    "    # Update x\n",
    "    image = scheduler_output.prev_sample\n",
    "\n",
    "    # Occasionally display both x and the predicted denoised images\n",
    "    if i % 10 == 0 or i == len(image_pipe.scheduler.timesteps) - 1:\n",
    "        plot_noise_and_denoise(scheduler_output, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](itr_1.png)\n",
    "![alt text](itr_2.png)\n",
    "![alt text](itr_3.png)\n",
    "![alt text](itr_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working along with the butterfly datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install genaibook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huggan/smithsonian_butterflies_subset\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "image_size = 64\n",
    "\n",
    "# Define data augmentations\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_size, image_size)),  # Resize\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip (data augmentation)\n",
    "        transforms.ToTensor(),  # Convert to tensor (0, 1)\n",
    "        transforms.Normalize([0.5], [0.5]),  # Map to (-1, 1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def transform(examples):\n",
    "    examples = [preprocess(image) for image in examples[\"image\"]]\n",
    "    return {\"images\": examples}\n",
    "\n",
    "\n",
    "dataset.set_transform(transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genaibook.core import show_images\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# When we normalized, we mapped (0, 1) to (-1, 1)\n",
    "# Now we map back to (0, 1) for display\n",
    "show_images(batch[\"images\"][:8] * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](normalised_butterfly.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adding Noise\n",
    "How do we gradually corrupt our data? The most common approach is to add noise to the images. We will add different amounts of noise to the training data, as the goal is to train a robust model to denoise no matter how much noise is in the input. The amount of noise we add is controlled by a noise schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "\n",
    "# We'll learn about beta_start and beta_end in the next sections\n",
    "scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000, beta_start=0.001, beta_end=0.02\n",
    ")\n",
    "timesteps = torch.linspace(0, 999, 8).long()\n",
    "\n",
    "# We load 8 images from the dataset and\n",
    "# add increasing amounts of noise to them\n",
    "x = batch[\"images\"][:8]\n",
    "noise = torch.rand_like(x)\n",
    "noised_x = scheduler.add_noise(x, noise, timesteps)\n",
    "show_images((noised_x * 0.5 + 0.5).clip(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](noised_img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UNNET Arch -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can set the device to either use our GPU or use our CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "\n",
    "# Create a UNet2DModel\n",
    "model = UNet2DModel(\n",
    "    in_channels=3,  # 3 channels for RGB images\n",
    "    sample_size=64,  # Specify our input size\n",
    "    # The number of channels per block affects the model size\n",
    "    block_out_channels=(64, 128, 256, 512),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\"AttnUpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"),\n",
    ").to(device)\n",
    "\n",
    "# Pass a batch of data through to see it works\n",
    "with torch.no_grad():\n",
    "    out = model(noised_x.to(device), timestep=timesteps.to(device)).sample\n",
    "\n",
    "print(noised_x.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data and model ready, let’s train it. For each training step, we:\n",
    "\n",
    "Load a batch of images.\n",
    "\n",
    "Add noise to the images. The amount of noise added depends on a specified number of timesteps: the more timesteps, the more noise. As mentioned, we want our model to denoise images with little noise and images with lots of noise. To achieve this, we’ll add random amounts of noise, so we’ll pick a random number of timesteps.\n",
    "\n",
    "Feed the noisy images into the model.\n",
    "\n",
    "Calculate the loss using mean squared error (MSE). MSE is a common loss function for regression tasks, including the UNet model’s noise prediction. It measures the average squared difference between predicted and true values, penalizing larger errors more. In the UNet model, MSE is calculated between predicted and actual noise, helping the model generate more realistic images by minimizing the loss. This is called the noise or epsilon objective.\n",
    "\n",
    "Backpropagate the loss and update the model weights with the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_epochs = 50  # How many runs through the data should we do?\n",
    "lr = 1e-4  # What learning rate should we use\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "losses = []  # Somewhere to store the loss values for later plotting\n",
    "\n",
    "# Train the model (this takes a while!)\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses = []  # Store losses for the current epoch\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        # Load the input images\n",
    "        clean_images = batch[\"images\"].to(device)\n",
    "\n",
    "        # Sample noise to add to the images\n",
    "        noise = torch.randn(clean_images.shape).to(device)\n",
    "\n",
    "        # Sample a random timestep for each image\n",
    "        timesteps = torch.randint(\n",
    "            0,\n",
    "            scheduler.config.num_train_timesteps,\n",
    "            (clean_images.shape[0],),\n",
    "            device=device,\n",
    "        ).long()\n",
    "\n",
    "        # Add noise to the clean images according\n",
    "        # to the noise magnitude at each timestep\n",
    "        noisy_images = scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "        # Get the model prediction for the noise\n",
    "        # The model also uses the timestep as an input\n",
    "        # for additional conditioning\n",
    "        noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "\n",
    "        # Compare the prediction with the actual noise\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "\n",
    "        # Store the loss for later plotting\n",
    "        losses.append(loss.item())\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "        # Update the model parameters with the optimizer based on this loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print the status for the current batch\n",
    "        if batch_idx % 32 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_dataloader)}], Loss: {loss.item()}\")\n",
    "\n",
    "    # Compute and print the average loss for the epoch\n",
    "    avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed, Average Loss: {avg_epoch_loss}\")\n",
    "\n",
    "# After training, print final status\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Training step\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(400, len(losses)), losses[400:])\n",
    "plt.title(\"Training loss from step 400\")\n",
    "plt.xlabel(\"Training step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](training_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMPipeline\n",
    "\n",
    "pipeline = DDPMPipeline(unet=model, scheduler=scheduler)\n",
    "ims = pipeline(batch_size=4).images\n",
    "show_images(ims, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pre_samp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random starting point (4 random images):\n",
    "sample = torch.randn(4, 3, 64, 64).to(device)\n",
    "\n",
    "for t in scheduler.timesteps:\n",
    "    # Get the model prediction\n",
    "    with torch.no_grad():\n",
    "        noise_pred = model(sample, t)[\"sample\"]\n",
    "\n",
    "    # Update sample with step\n",
    "    sample = scheduler.step(noise_pred, t, sample).prev_sample\n",
    "\n",
    "show_images(sample.clip(-1, 1) * 0.5 + 0.5, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](post_samp.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
