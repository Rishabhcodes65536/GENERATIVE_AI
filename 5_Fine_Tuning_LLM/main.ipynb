{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"ag_news\")\n",
    "raw_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['text', 'label'],\n",
    "        num_rows: 120000\n",
    "    })\n",
    "    test: Dataset({\n",
    "        features: ['text', 'label'],\n",
    "        num_rows: 7600\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset = raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
    " 'label': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_train_dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['World', 'Sports', 'Business', 'Sci/Tech'], id=None)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"], truncation=True, padding=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "\n",
    "tokenize_function(raw_train_dataset[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'input_ids': tensor([[  101,  2813,  2358,  1012,  6468, 15020,  2067,  2046,  1996,  2304,\n",
    "          1006, 26665,  1007, 26665,  1011,  2460,  1011, 19041,  1010,  2813,\n",
    "          2395,  1005,  1055,  1040, 11101,  2989,  1032,  2316,  1997, 11087,\n",
    "          1011, 22330,  8713,  2015,  1010,  2024,  3773,  2665,  2153,  1012,\n",
    "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0],\n",
    "        [  101, 18431,  2571,  3504,  2646,  3293, 13395,  1006, 26665,  1007,\n",
    "         26665,  1011,  2797,  5211,  3813, 18431,  2571,  2177,  1010,  1032,\n",
    "          2029,  2038,  1037,  5891,  2005,  2437,  2092,  1011, 22313,  1998,\n",
    "          5681,  1032,  6801,  3248,  1999,  1996,  3639,  3068,  1010,  2038,\n",
    "          5168,  2872,  1032,  2049, 29475,  2006,  2178,  2112,  1997,  1996,\n",
    "          3006,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1]])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
    "        num_rows: 120000\n",
    "    })\n",
    "    test: Dataset({\n",
    "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
    "        num_rows: 7600\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "print(accuracy.description)\n",
    "print(accuracy.compute(references=[0, 1, 0, 1], predictions=[1, 0, 0, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with:\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    " Where:\n",
    "TP: True positive\n",
    "TN: True negative\n",
    "FP: False positive\n",
    "FN: False negative\n",
    "\n",
    "{'accuracy': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    # Compute F1 score and accuracy\n",
    "    f1 = f1_score.compute(\n",
    "        references=labels, predictions=preds, average=\"weighted\"\n",
    "    )[\n",
    "        \"f1\"\n",
    "    ]\n",
    "    acc = accuracy.compute(references=labels, predictions=preds)[\n",
    "        \"accuracy\"\n",
    "    ]\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_labels = 4\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=num_labels\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U accelerate\n",
    "!pip install -U transformers\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size=32\n",
    "training_args = TrainingArguments(\n",
    "    \"trainer-chapter4\",\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "shuffled_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "small_split = shuffled_dataset.select(range(10000))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=small_split,\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer inner working summarize similar\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5) 1\n",
    "lr_scheduler = get_scheduler(\"linear\", ...) 2\n",
    "\n",
    "for epoch in range(num_epochs): 3\n",
    "    for batch in train_dataloader: 4\n",
    "        batch = {k: v.to(device) for k, v in batch.items()} 5\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss 6\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step() 7\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"osanseviero/trainer-chapter4\")\n",
    "pipe(\n",
    "    \"\"\"The soccer match between Spain and\n",
    "Portugal ended in a terrible result for Portugal.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config.json: 100%\n",
    " 807/807 [00:00<00:00, 11.6kB/s]\n",
    "model.safetensors: 100%\n",
    " 268M/268M [00:11<00:00, 23.9MB/s]\n",
    "tokenizer_config.json: 100%\n",
    " 1.20k/1.20k [00:00<00:00, 39.8kB/s]\n",
    "vocab.txt: 100%\n",
    " 232k/232k [00:00<00:00, 518kB/s]\n",
    "tokenizer.json: 100%\n",
    " 712k/712k [00:00<00:00, 1.62MB/s]\n",
    "special_tokens_map.json: 100%\n",
    " 125/125 [00:00<00:00, 3.80kB/s]\n",
    "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
    "[{'label': 'LABEL_1', 'score': 0.9330371022224426}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[\"test\"].select([0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset({\n",
    "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
    "    num_rows: 3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference for all samples\n",
    "trainer_preds = trainer.predict(tokenized_datasets[\"test\"])\n",
    "\n",
    "# Get the most likely class and the target label\n",
    "preds = trainer_preds.predictions.argmax(-1)\n",
    "references = trainer_preds.label_ids\n",
    "label_names = raw_train_dataset.features[\"label\"].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results of the first 3 samples\n",
    "samples = 7\n",
    "texts = tokenized_datasets[\"test\"][\"text\"][:samples]\n",
    "\n",
    "for pred, ref, text in zip(preds[:samples], references[:samples], texts):\n",
    "    print(f\"Predicted {pred}; Actual {ref}; Target name: {label_names[pred]}.\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted 2; Actual 2; Target name: Business.\n",
    "Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\n",
    "Predicted 3; Actual 3; Target name: Sci/Tech.\n",
    "The Race is On: Second Private Team Sets Launch Date for Human Spaceflight (SPACE.com) SPACE.com - TORONTO, Canada -- A second\\team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket.\n",
    "Predicted 3; Actual 3; Target name: Sci/Tech.\n",
    "Ky. Company Wins Grant to Study Peptides (AP) AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.\n",
    "Predicted 3; Actual 3; Target name: Sci/Tech.\n",
    "Prediction Unit Helps Forecast Wildfires (AP) AP - It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already he knows what the day will bring. Lightning will strike in places he expects. Winds will pick up, moist places will dry and flames will roar.\n",
    "Predicted 3; Actual 3; Target name: Sci/Tech.\n",
    "Calif. Aims to Limit Farm-Related Smog (AP) AP - Southern California's smog-fighting agency went after emissions of the bovine variety Friday, adopting the nation's first rules to reduce air pollution from dairy cow manure.\n",
    "Predicted 3; Actual 3; Target name: Sci/Tech.\n",
    "Open Letter Against British Copyright Indoctrination in Schools The British Department for Education and Skills (DfES) recently launched a \"Music Manifesto\" campaign, with the ostensible intention of educating the next generation of British musicians. Unfortunately, they also teamed up with the music industry (EMI, and various artists) to make this popular. EMI has apparently negotiated their end well, so that children in our schools will now be indoctrinated about the illegality of downloading music.The ignorance and audacity of this got to me a little, so I wrote an open letter to the DfES about it. Unfortunately, it's pedantic, as I suppose you have to be when writing to goverment representatives. But I hope you find it useful, and perhaps feel inspired to do something similar, if or when the same thing has happened in your area.\n",
    "Predicted 3; Actual 3; Target name: Sci/Tech.\n",
    "Loosing the War on Terrorism \\\\\"Sven Jaschan, self-confessed author of the Netsky and Sasser viruses, is\\responsible for 70 percent of virus infections in 2004, according to a six-month\\virus roundup published Wednesday by antivirus company Sophos.\"\\\\\"The 18-year-old Jaschan was taken into custody in Germany in May by police who\\said he had admitted programming both the Netsky and Sasser worms, something\\experts at Microsoft confirmed. (A Microsoft antivirus reward program led to the\\teenager's arrest.) During the five months preceding Jaschan's capture, there\\were at least 25 variants of Netsky and one of the port-scanning network worm\\Sasser.\"\\\\\"Graham Cluley, senior technology consultant at Sophos, said it was staggeri ...\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "confusion_matrix = evaluate.load(\"confusion_matrix\")\n",
    "cm = confusion_matrix.compute(\n",
    "    references=references, predictions=preds, normalize=\"true\"\n",
    ")[\"confusion_matrix\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
    "disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "\n",
    "plt.title(\"Normalized confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](confusion_mat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating business news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_datasets = raw_datasets.filter(lambda example: example[\"label\"] == 2)\n",
    "filtered_datasets = filtered_datasets.remove_columns(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_id = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = (\n",
    "    tokenizer.eos_token\n",
    ")  # Needed as gpt2 does not specify padding token.\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = filtered_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],  # We only need the input_ids and attention_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['input_ids', 'attention_mask'],\n",
    "        num_rows: 30000\n",
    "    })\n",
    "    test: Dataset({\n",
    "        features: ['input_ids', 'attention_mask'],\n",
    "        num_rows: 1900\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [tokenized_datasets[\"train\"][i] for i in range(3)]\n",
    "\n",
    "for sample in samples:\n",
    "    print(f\"input_ids shape: {len(sample['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_ids shape: 37\n",
    "input_ids shape: 55\n",
    "input_ids shape: 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = data_collator(samples)\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_ids shape: torch.Size([3, 55])\n",
    "attention_mask shape: torch.Size([3, 55])\n",
    "labels shape: torch.Size([3, 55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"sft_cml4\",\n",
    "    push_to_hub=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    weight_decay=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"].select(range(5000)),\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step\tTraining Loss\tValidation Loss\n",
    "200\t3.659400\t3.597305\n",
    "400\t3.310700\t3.490597\n",
    "600\t3.098700\t3.372308\n",
    "800\t2.144300\t3.444029\n",
    "1000\t1.964900\t3.415928\n",
    "1200\t1.910900\t3.402368\n",
    "TrainOutput(global_step=1250, training_loss=2.6508543701171874, metrics={'train_runtime': 431.686, 'train_samples_per_second': 23.165, 'train_steps_per_second': 2.896, 'total_flos': 467451445248000.0, 'train_loss': 2.6508543701171874, 'epoch': 2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"Rishabh-sucks-at-code/sft_cml4\", device=device)\n",
    "pipe.tokenizer.pad_token_id = 50256  # pad_token_id for gpt2\n",
    "print(pipe(\"Q1\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"])\n",
    "print(pipe(\"Wall\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"])\n",
    "print(pipe(\"Google\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 profit soars in Q2 as US bookies flourish A new spate of bookies and bookies reports the full year net profit for the year to June 30, helped by strong domestic bookies and strong results for August this year. The\n",
    "Wall St. Seen Lower as Oil Prices Weighs  NEW YORK (Reuters) - Wall Street is seen lowering  shares of extremely risky mutual funds on Thursday, as a drop in oil prices threatens to  stun Wall Street's long-term growth\n",
    "Google, S goes public on IPO NEW YORK, August 19 (New Ratings)  Google, the worlds most popular Internet search engine, announced its public shares registration today just hours after initial public offering.   The highly anticipated IPO was announced on Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wrapped(text):\n",
    "    print(\"=\" * 20)\n",
    "    print(text)\n",
    "    print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrapped(\n",
    "    pipe(\"Q1\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"]\n",
    ")\n",
    "print_wrapped(\n",
    "    pipe(\"Wall\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"]\n",
    ")\n",
    "print_wrapped(\n",
    "    pipe(\"Google\", pad_token_id=tokenizer.eos_token_id)[0][\"generated_text\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================\n",
    "Q1 profit beats forecasts The Australian Securities Exchange Commission (SXC) on Tuesday reported its first profit since 2003, buoyed by easing drug prices and strong sales from pharmacies.  quot;Success or failure? quot; The firm reported that first\n",
    "====================\n",
    "====================\n",
    "Wall Street Is Set to Open Lower  NEW YORK (Reuters) - The Dow Jones Industrial Average  closed lower on Wednesday as investors were encouraged in the  latest week to return to the casino stock market and seek bargains  out of the Big Three\n",
    "====================\n",
    "====================\n",
    "Google IPO Price Range Is Over \\$85  NEW YORK/SAN FRANCISCO (Reuters) - Google Inc. &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?t\n",
    "===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performace Efficient Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    fan_in_fan_out=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.2364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantization\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", torch_dtype=\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def scaling_factor(vector):\n",
    "    m = np.max(np.abs(vector))\n",
    "    return 127 / m\n",
    "\n",
    "\n",
    "array = [1.2, -0.5, -4.3, 1.2, -3.1, 0.8, 2.4, 5.4]\n",
    "alpha = scaling_factor(array)\n",
    "quantized_array = np.round(alpha * np.array(array)).astype(np.int8)\n",
    "dequantized_array = quantized_array / alpha\n",
    "\n",
    "print(f\"Scaling factor: {alpha}\")\n",
    "print(f\"Quantized array: {quantized_array}\")\n",
    "print(f\"Dequantized array: {dequantized_array}\")\n",
    "print(f\"Difference: {array - dequantized_array}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling factor: 23.518518518518515\n",
    "Quantized array: [  28  -12 -101   28  -73   19   56  127]\n",
    "Dequantized array: [ 1.19055118 -0.51023622 -4.29448819  1.19055118 -3.10393701  0.80787402\n",
    "  2.38110236  5.4       ]\n",
    "Difference: [ 0.00944882  0.01023622 -0.00551181  0.00944882  0.00393701 -0.00787402\n",
    "  0.01889764  0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\", split=\"train\")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"sft_cml5\",\n",
    "    push_to_hub=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    weight_decay=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=200,\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset.select(range(300)),\n",
    "    dataset_text_field=\"text\",\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    \"osanseviero/sft_cml5\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model = model.merge_and_unload()  # This is the main difference\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "pipe(\"### Human: Hello!###Assistant:\", max_new_tokens=100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
